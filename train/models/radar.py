import transformers
import torch
import torch.nn.functional as F
import numpy as np
import random

class RADAR:
    def __init__(self, detector_path_or_id="TrustSafeAI/RADAR-Vicuna-7B"):
        self.device = "cuda:0"
        self.detector = transformers.AutoModelForSequenceClassification.from_pretrained(detector_path_or_id)
        self.tokenizer = transformers.AutoTokenizer.from_pretrained(detector_path_or_id)
        self.detector.eval()
        self.detector.to(self.device)
        self.features = []
        
    def detect_probability(self, text):
        with torch.no_grad():
            inputs = self.tokenizer([text], padding=True, truncation=True, max_length=512, return_tensors="pt")
            inputs = {k:v.to(self.device) for k,v in inputs.items()}
            output_probs = F.log_softmax(self.detector(**inputs).logits,-1)[:,0].exp().tolist()
        # output_probs is the probability that the input_text is generated by LLM.
        return output_probs[0]
