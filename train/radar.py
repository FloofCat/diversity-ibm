import transformers
import torch
import torch.nn.functional as F
import numpy as np
import random

class RADAR:
    def __init__(self, model, tokenizer):
        self.detector = model
        self.tokenizer = tokenizer
        self.detector.eval()
        self.detector.to(self.device)
        self.features = []
        
    def detect_probability(self, text):
        with torch.no_grad():
            inputs = self.tokenizer([text], padding=True, truncation=True, max_length=512, return_tensors="pt")
            inputs = {k:v.to(self.detector.device) for k,v in inputs.items()}
            output_probs = F.log_softmax(self.detector(**inputs).logits,-1)[:,0].exp().tolist()
        # output_probs is the probability that the input_text is generated by LLM.
        return output_probs[0]
